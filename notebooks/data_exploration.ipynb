{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "- interactive meaningful visualizations\n",
    "- some descriptive metrics of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local path to the data\n",
    "PATH = \"/Users/flohmann/Documents/ETH/FS2024/datathon24/skylab_instagram_datathon_dataset.csv\" \n",
    "\n",
    "X = pd.read_csv(PATH, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count unique values in every column\n",
    "X.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can remove calculation_type and period since they do not provide any information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some basic dataset statistics\n",
    "nrow = len(X.index)\n",
    "nbrand = X.business_entity_doing_business_as_name.nunique()\n",
    "start_date = X.period_end_date.min()\n",
    "end_date = X.period_end_date.max()\n",
    "\n",
    "# largest and smallest compset groups\n",
    "ngroup = X.compset_group.nunique()\n",
    "min_group = X.groupby('compset_group').business_entity_doing_business_as_name.nunique().sort_values().iloc[-1]\n",
    "max_group = X.groupby('compset_group').business_entity_doing_business_as_name.nunique().sort_values().iloc[0]\n",
    "\n",
    "print(f'The dataset contains {nrow} observations from {nbrand} brands that were recorded in the period from {start_date} to {end_date}.')\n",
    "print(f'Brands are grouped into {ngroup} main competitive sets that vary in size from {max_group} brands to {min_group} brands')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.groupby('compset_group').business_entity_doing_business_as_name.nunique().sort_values(ascending=False).plot(kind='bar')\n",
    "plt.ylabel('# brands')\n",
    "plt.xlabel('group name')\n",
    "plt.title('Main competitive group sizes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of data over time\n",
    "\n",
    "Are the dates equally distributed for every brand?\n",
    "This is relevant for applying LSTM models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Recording stops on the same date for all brands : {X.groupby('business_entity_doing_business_as_name').period_end_date.max().unique()[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# plot distribution of recording start dates\n",
    "X.groupby('business_entity_doing_business_as_name').period_end_date.min().sort_values().hist(xrot=90, ax=ax, bins = 20, grid=False)\n",
    "tick_labs = ax.get_xticklabels()\n",
    "ticks = ax.get_xticks()\n",
    "ax.set_xticks(ticks[::5], tick_labs[::5])\n",
    "ax.set_ylabel('# brands')\n",
    "ax.set_title('Distribution of starting dates')\n",
    "\n",
    "fig.set_figwidth(7)\n",
    "fig.set_figheight(5)\n",
    "fig.tight_layout()\n",
    "\n",
    "print('Recording of different brands starts at different dates, but the majority starts on the same date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{sum(X.groupby('business_entity_doing_business_as_name').period_end_date.min()>'2015-01-03')} brands start at a later date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [c for c in X.columns if c != 'compset_group' and c != 'compset']\n",
    "n_duplicates = len(X)-len(X.drop_duplicates(subset=cols))\n",
    "\n",
    "print(f'{n_duplicates} datapoints occurr as duplicates in multiple compsets or compset_groups')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_uniq = X.drop_duplicates(subset=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.groupby('compset_group').compset.nunique().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = X.groupby('compset').compset_group.nunique() > 1\n",
    "X.groupby('compset').compset_group.unique()[msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.groupby('compset').compset_group.nunique()[msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Columns with nan values are {X.columns[X.isna().sum(axis=0)>0].tolist()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns without nans\n",
    "X.columns[X.isna().sum(axis=0)==0].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All brands are either traded at the same stock exchange over the entire recording period or at no exchange at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(X.groupby('business_entity_doing_business_as_name').primary_exchange_name.nunique()>1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are stock prices a viable metric for validation? We need to check whether all brands are registered at some stock exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{X[X.primary_exchange_name.isna()].business_entity_doing_business_as_name.nunique()}/{X.business_entity_doing_business_as_name.nunique()} brands have no stock exchange recorded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns that do not contain any nans can potentially be used to construct a unique identifier. We use period_end_date and business_entity_doing_business_as_name\n",
    "\n",
    "### Nans in numeric columns\n",
    "\n",
    "Now we want to look at the the rows that contain missing values in the numeric columns to better understand where these occurr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_uniq.iloc[:,-5:].isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk_nanrows = X_uniq.iloc[:,-5:].isna().sum(axis = 1) > 0\n",
    "msk_nanrows.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_uniq[msk_nanrows].business_entity_doing_business_as_name.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_uniq[msk_nanrows].business_entity_doing_business_as_name.value_counts().hist(bins=100)\n",
    "plt.xlabel('# nan values')\n",
    "plt.ylabel('# brands')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there brands that always have nans for some attribute?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_frac = X_uniq[['business_entity_doing_business_as_name', 'followers', 'pictures',\n",
    "       'videos', 'comments', 'likes']].groupby('business_entity_doing_business_as_name').apply(lambda x: x.iloc[:,1:].isna().sum()/len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_frac[na_frac.max(axis=1) > 0.7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Country names\n",
    "Some country names contain semicolons, we want to strip these extra characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.domicile_country_name.unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
