{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/david/code/datathon24-personal/data/skylab_instagram_datathon_dataset.csv\"\n",
    "# DATA_PATH = \"/Users/flohmann/Documents/ETH/FS2024/datathon24/skylab_instagram_datathon_dataset.csv\"\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(DATA_PATH, sep=\";\")\n",
    "\n",
    "\n",
    "def video_to_picture_ratio(df, videos_col, pictures_col):\n",
    "    df['video_picture_ratio'] = df[videos_col] / df[pictures_col]\n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_rolling_average_per_brand(data, brand_column, window_size=7):\n",
    "    \"\"\"\n",
    "    Calculate the rolling average of 'engagement' for each brand in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        data (pd.DataFrame): The DataFrame containing the data.\n",
    "        brand_column (str): The column name which identifies the brand.\n",
    "        window_size (int): The number of observations used for calculating the rolling average.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with a new column for the rolling average of 'engagement' calculated per brand.\n",
    "    \"\"\"\n",
    "    # Group by brand and calculate rolling average within each group\n",
    "    data['rolling_avg_engagement'] = data.groupby(brand_column)['engagement'].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
    "    return data\n",
    "\n",
    "\n",
    "def calculate_exponential_moving_average_per_brand(data, brand_column, span=7):\n",
    "    \"\"\"\n",
    "    Calculate the exponential moving average of 'engagement' for each brand in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        data (pd.DataFrame): The DataFrame containing the data.\n",
    "        brand_column (str): The column name which identifies the brand.\n",
    "        span (int): The decay in terms of the span of the exponential window.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with a new column for the exponential moving average of 'engagement' calculated per brand.\n",
    "    \"\"\"\n",
    "    # Group by brand and calculate EMA within each group\n",
    "    data['ewma_engagement'] = data.groupby(brand_column)['engagement'].transform(lambda x: x.ewm(span=span, adjust=False).mean())\n",
    "    return data\n",
    "\n",
    "\n",
    "def calculate_brand_wise_growth_rates(data, column_names, brand_column):\n",
    "    \"\"\"\n",
    "    Calculate the growth rate for specified columns in a DataFrame, grouped by brand.\n",
    "    Replace NaN values with 0 where growth rate cannot be calculated.\n",
    "\n",
    "    Parameters:\n",
    "        data (pd.DataFrame): The DataFrame containing the data.\n",
    "        column_names (list of str): A list of column names to calculate the growth rate.\n",
    "        brand_column (str): The column name which identifies the brand.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with new columns for each specified column's growth rate, calculated for each brand and NaN replaced by 0.\n",
    "    \"\"\"\n",
    "    for column in column_names:\n",
    "        # Calculate growth rate within each brand group\n",
    "        data[f'growth_rate_{column}'] = data.groupby(brand_column)[column].pct_change() * 100\n",
    "        # Replace NaN values with 0\n",
    "        data[f'growth_rate_{column}'].fillna(0, inplace=True)\n",
    "    return data\n",
    "\n",
    "def calculate_brand_rolling_statistics(data, column_name, brand_column, window_size=7):\n",
    "    \"\"\"\n",
    "    Calculate rolling statistics for a specified column in a DataFrame, grouped by brand,\n",
    "    and replace NaN values with 0.\n",
    "\n",
    "    Parameters:\n",
    "        data (pd.DataFrame): The DataFrame containing the data.\n",
    "        column_name (str): The column name to calculate rolling statistics.\n",
    "        brand_column (str): The column name which identifies the brand.\n",
    "        window_size (int): The number of observations used for calculating the rolling statistic.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with new columns for each rolling statistic of the specified column, calculated for each brand.\n",
    "    \"\"\"\n",
    "    grouped = data.groupby(brand_column)[column_name]\n",
    "    data[f'{column_name}_rolling_min'] = grouped.transform(lambda x: x.rolling(window=window_size, min_periods=1).min()).fillna(0)\n",
    "    data[f'{column_name}_rolling_max'] = grouped.transform(lambda x: x.rolling(window=window_size, min_periods=1).max()).fillna(0)\n",
    "    data[f'{column_name}_rolling_std'] = grouped.transform(lambda x: x.rolling(window=window_size, min_periods=1).std()).fillna(0)\n",
    "\n",
    "    return data\n",
    "\n",
    "def create_brand_lag_features(data, column_name, brand_column, lag_periods):\n",
    "    \"\"\"\n",
    "    Create lag features for a specified column in a DataFrame, grouped by brand,\n",
    "    and replace NaN values with 0.\n",
    "\n",
    "    Parameters:\n",
    "        data (pd.DataFrame): The DataFrame containing the data.\n",
    "        column_name (str): The column name to create lag features for.\n",
    "        brand_column (str): The column name which identifies the brand.\n",
    "        lag_periods (int): The number of lag periods.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with new columns for each lag feature of the specified column, calculated for each brand.\n",
    "    \"\"\"\n",
    "    for i in range(1, lag_periods + 1):\n",
    "        data[f'{column_name}_lag_{i}'] = data.groupby(brand_column)[column_name].shift(i).fillna(0)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def preprocess_data(df, missing_values_cutoff=0.7, test_fraction=0.2):\n",
    "\n",
    "    df = df.drop(columns=[\"period\", \"calculation_type\", \"compset\", \"compset_group\", \"legal_entity_name\", \"ultimate_parent_legal_entity_name\", \"primary_exchange_name\"])\n",
    "    df[\"period_end_date\"] = pd.to_datetime(df[\"period_end_date\"])\n",
    "\n",
    "    df = df.rename(columns={'business_entity_doing_business_as_name': 'brand', 'period_end_date': 'date'})\n",
    "\n",
    "    # Remove specific brands, invalid or with too much missing data\n",
    "    df = df[df['brand'] != \"All Brands\"]\n",
    "    df = df[df['brand'] != \"Boca\"]\n",
    "    df = df[df['brand'] != \"Bulgari Beauty\"]\n",
    "\n",
    "    df = df.groupby(['brand', 'date']).first().reset_index()\n",
    "\n",
    "    def correct_country_name(name):\n",
    "        country_map = {\n",
    "            \"Hong Kong\": \"China\",\n",
    "            \"China;Hong Kong\": \"China\",\n",
    "            \";France\": \"France\",\n",
    "            \";\": None,\n",
    "            \"Belgium;\": \"Belgium\"\n",
    "        }\n",
    "        if name in country_map.keys():\n",
    "            return country_map[name]\n",
    "        return name\n",
    "\n",
    "    df['domicile_country_name'] = df['domicile_country_name'].apply(correct_country_name)\n",
    "\n",
    "\n",
    "    categorical_features = [\"domicile_country_name\"]\n",
    "    for feature in categorical_features:\n",
    "        df = pd.get_dummies(df, columns=[feature], prefix=feature, dummy_na=True, dtype=int)\n",
    "\n",
    "    # TODO: remove bad data\n",
    "    na_frac = df[['brand', 'followers', 'pictures',\n",
    "        'videos', 'comments', 'likes']].groupby('brand').apply(lambda x: x.iloc[:,1:].isna().sum()/len(x))\n",
    "\n",
    "    bad_brands = list(na_frac[na_frac.max(axis=1) > missing_values_cutoff].index)\n",
    "\n",
    "    df = df[~df['brand'].isin(bad_brands)]\n",
    "\n",
    "\n",
    "    # TODO: add additional features\n",
    "    df['engagement'] = df['comments'] + df['likes']\n",
    "    df['engagement_rate'] = df['engagement']/df['followers']\n",
    "    df['engagement_rate_per_post'] =  df['engagement_rate']/(df['videos'] + df['pictures'])\n",
    "\n",
    "\n",
    "    # df = video_to_picture_ratio(df, \"videos\", \"pictures\")\n",
    "    df = calculate_rolling_average_per_brand(df, \"brand\", window_size=4)\n",
    "    df = calculate_exponential_moving_average_per_brand(df, \"brand\", span=4)\n",
    "    # df = calculate_brand_wise_growth_rates(df, [\"comments\", \"likes\", \"followers\", \"pictures\", \"videos\"], \"brand\")\n",
    "    for c in [\"comments\", \"likes\", \"followers\", \"pictures\", \"videos\"]:\n",
    "        df = calculate_brand_rolling_statistics(df, c, \"brand\", window_size=4)\n",
    "        df = create_brand_lag_features(df, c, \"brand\", 4)\n",
    "\n",
    "    \n",
    "    # Step 1: Sort the dataframe by time\n",
    "    df_sorted = df.sort_values(by='date')\n",
    "\n",
    "    # Step 2: Group the dataframe by 'Brand'\n",
    "    grouped = df_sorted.groupby('brand')\n",
    "\n",
    "    # Step 3: Define an empty dataframe for train and test sets\n",
    "    train_df = pd.DataFrame(columns=df.columns)  # Columns same as original dataframe\n",
    "    test_df = pd.DataFrame(columns=df.columns)   # Columns same as original dataframe\n",
    "\n",
    "    # Step 4: Iterate over each group and split into train and test sets\n",
    "    for _, group in grouped:\n",
    "        n_rows = len(group)\n",
    "        n_test = int(test_fraction * n_rows)  # 20% of rows for test set\n",
    "\n",
    "        # Add last 20% of rows to test set\n",
    "        test_df = pd.concat([test_df, group.iloc[-n_test:]])\n",
    "\n",
    "        # Add remaining rows to train set\n",
    "        train_df = pd.concat([train_df, group.iloc[:-n_test]])\n",
    "\n",
    "    # Step 5: Reset index for both train and test dataframes\n",
    "    train_df.reset_index(drop=True, inplace=True)\n",
    "    test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "    # normalize values\n",
    "    normalize_cols = [c for c in train_df.columns if c not in ['brand', 'date'] and not c.startswith(\"domicile_country_name\")]\n",
    "    for col in normalize_cols:\n",
    "        m = train_df[col].mean()\n",
    "        s = train_df[col].std()\n",
    "        train_df[col] = (train_df[col] - m)/s\n",
    "        test_df[col] = (test_df[col] - m)/s\n",
    "\n",
    "\n",
    "  \n",
    "    # impute missing values\n",
    "    train_df = train_df.groupby('brand').apply(lambda group: group.fillna(method='ffill'))\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "    train_df = train_df.groupby('brand').apply(lambda group: group.fillna(method='bfill'))\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "    test_df = test_df.groupby('brand').apply(lambda group: group.fillna(method='ffill'))\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "    test_df = test_df.groupby('brand').apply(lambda group: group.fillna(method='bfill'))\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "def prepare_data_lstm(df, sequence_length=10, prediction_dist=4, missing_values_cutoff=0.7, test_fraction=0.2):\n",
    "\n",
    "    df = df.drop(columns=[\"period\", \"calculation_type\", \"compset\", \"compset_group\", \"legal_entity_name\", \"ultimate_parent_legal_entity_name\", \"primary_exchange_name\"])\n",
    "    df[\"period_end_date\"] = pd.to_datetime(df[\"period_end_date\"])\n",
    "\n",
    "    df = df.rename(columns={'business_entity_doing_business_as_name': 'brand', 'period_end_date': 'date'})\n",
    "\n",
    "    df = df[df['brand'] != \"All Brands\"]\n",
    "    df = df[df['brand'] != \"Boca\"]\n",
    "    df = df[df['brand'] != \"Bulgari Beauty\"]\n",
    "\n",
    "    df = df.groupby(['brand', 'date']).first().reset_index()\n",
    "\n",
    "    def correct_country_name(name):\n",
    "        country_map = {\n",
    "            \"Hong Kong\": \"China\",\n",
    "            \"China;Hong Kong\": \"China\",\n",
    "            \";France\": \"France\",\n",
    "            \";\": None,\n",
    "            \"Belgium;\": \"Belgium\"\n",
    "        }\n",
    "        if name in country_map.keys():\n",
    "            return country_map[name]\n",
    "        return name\n",
    "    \n",
    "    df = df.drop(columns=['domicile_country_name'])\n",
    "\n",
    "\n",
    "    # remove bad data\n",
    "    na_frac = df[['brand', 'followers', 'pictures',\n",
    "        'videos', 'comments', 'likes']].groupby('brand').apply(lambda x: x.iloc[:,1:].isna().sum()/len(x))\n",
    "\n",
    "    bad_brands = list(na_frac[na_frac.max(axis=1) > missing_values_cutoff].index)\n",
    "\n",
    "    df = df[~df['brand'].isin(bad_brands)]\n",
    "\n",
    "\n",
    "    # compute labels\n",
    "    df['engagement'] = df['comments'] + df['likes']\n",
    "    df['engagement_rate'] = df['engagement']/df['followers']\n",
    "    df['engagement_rate_per_post'] =  df['engagement_rate']/(df['videos'] + df['pictures'])\n",
    "\n",
    "\n",
    "    for c in [\"comments\", \"likes\", \"followers\", \"pictures\", \"videos\"]:\n",
    "        df = calculate_brand_rolling_statistics(df, c, \"brand\", window_size=4)\n",
    "        df = create_brand_lag_features(df, c, \"brand\", 4)\n",
    "\n",
    "    # Sort the dataframe by time\n",
    "    df_sorted = df.sort_values(by='date')\n",
    "\n",
    "    # Group the dataframe by 'Brand'\n",
    "    grouped = df_sorted.groupby('brand')\n",
    "\n",
    "    # Define an empty dataframe for train and test sets\n",
    "    train_df = pd.DataFrame(columns=df.columns)  # Columns same as original dataframe\n",
    "    test_df = pd.DataFrame(columns=df.columns)   # Columns same as original dataframe\n",
    "\n",
    "    # Iterate over each group and split into train and test sets\n",
    "    for _, group in grouped:\n",
    "        n_rows = len(group)\n",
    "        n_test = int(test_fraction * n_rows)  # 20% of rows for test set\n",
    "\n",
    "        # Add last 20% of rows to test set\n",
    "        test_df = pd.concat([test_df, group.iloc[-n_test:]])\n",
    "\n",
    "        # Add remaining rows to train set\n",
    "        train_df = pd.concat([train_df, group.iloc[:-n_test]])\n",
    "\n",
    "    # Step 5: Reset index for both train and test dataframes\n",
    "    train_df.reset_index(drop=True, inplace=True)\n",
    "    test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "    # normalize values\n",
    "\n",
    "    normalize_cols = [c for c in train_df.columns if c not in ['brand', 'date'] and not c.startswith(\"domicile_country_name\")]\n",
    "    for col in normalize_cols:\n",
    "        m = train_df[col].mean()\n",
    "        s = train_df[col].std()\n",
    "        train_df[col] = (train_df[col] - m)/s\n",
    "        test_df[col] = (test_df[col] - m)/s\n",
    "\n",
    "\n",
    "    # impute missing values\n",
    "    train_df = train_df.groupby('brand').apply(lambda group: group.fillna(method='ffill'))\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "    train_df = train_df.groupby('brand').apply(lambda group: group.fillna(method='bfill'))\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "    test_df = test_df.groupby('brand').apply(lambda group: group.fillna(method='ffill'))\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "    test_df = test_df.groupby('brand').apply(lambda group: group.fillna(method='bfill'))\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "    label_col = \"engagement_rate_per_post\"\n",
    "\n",
    "    train_sequences = []\n",
    "    train_labels = []\n",
    "    test_sequences = []\n",
    "    test_labels = []\n",
    "\n",
    "    test_brands = []\n",
    "\n",
    "    for bi, brand in enumerate(df['brand'].unique()):\n",
    "\n",
    "        brand_train_df = train_df[train_df['brand'] == brand]\n",
    "\n",
    "        cols = [c for c in train_df.columns if (c != \"brand\" and c != \"date\")]\n",
    "        brand_train_df = brand_train_df[cols]\n",
    "\n",
    "        for i in range(len(brand_train_df) - (sequence_length + prediction_dist)):\n",
    "            \n",
    "\n",
    "            sequence_labels = brand_train_df.iloc[i+sequence_length+prediction_dist][label_col]\n",
    "            train_labels.append(sequence_labels)\n",
    "\n",
    "            sequence = brand_train_df.iloc[i:i + sequence_length]\n",
    "\n",
    "            # remove labels\n",
    "            sequence = sequence.drop(columns=[\"engagement\", \"engagement_rate\", \"engagement_rate_per_post\"])\n",
    "            \n",
    "            sequence = sequence.values\n",
    "            train_sequences.append(sequence)\n",
    "        \n",
    "        brand_test_df = test_df[test_df['brand'] == brand]\n",
    "\n",
    "        brand_test_df = brand_test_df[cols]\n",
    "\n",
    "\n",
    "        for i in range(len(brand_test_df) - (sequence_length + prediction_dist)):\n",
    "\n",
    "            sequence_labels = brand_test_df.iloc[i+sequence_length+prediction_dist][label_col]\n",
    "\n",
    "            sequence = brand_test_df.iloc[i:i + sequence_length]\n",
    "\n",
    "            # remove labels\n",
    "            sequence = sequence.drop(columns=[\"engagement\", \"engagement_rate\", \"engagement_rate_per_post\"])\n",
    "\n",
    "            sequence = sequence.values\n",
    "            if (np.isnan(sequence).any()):\n",
    "                continue\n",
    "\n",
    "            if np.isnan(sequence_labels).any():\n",
    "                continue \n",
    "            \n",
    "            test_sequences.append(sequence)\n",
    "\n",
    "            test_labels.append(sequence_labels)\n",
    "\n",
    "            test_brands.append(brand)\n",
    "\n",
    "\n",
    "    return train_sequences, train_labels, test_sequences, test_labels, \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Global device configuration\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "\n",
    "    torch.device('mps')\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size//2)\n",
    "        self.fc2 = nn.Linear(hidden_size//2, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        # self.bn = nn.BatchNorm1d(hidden_size//2)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through LSTM layer\n",
    "        # x shape: (batch, sequence_length, input_size)\n",
    "        out, (h_t, c_t) = self.lstm(x)\n",
    "\n",
    "        # We use the last hidden state to predict the output\n",
    "        # h_t shape: (num_layers, batch, hidden_size)\n",
    "        # Take the last layer's hidden state\n",
    "        h_t_last_layer = h_t[-1]\n",
    "\n",
    "        # Forward pass through the fully connected layer\n",
    "        x = self.relu(self.fc1(h_t_last_layer))\n",
    "        # x = self.bn(x)\n",
    "        out = self.fc2(x)\n",
    "\n",
    "\n",
    "        return out\n",
    "\n",
    "def initialize_data_loader(X, y, batch_size):\n",
    "    # Convert list of numpy arrays to a list of torch tensors\n",
    "    X_tensors = [torch.tensor(sequence, dtype=torch.float32) for sequence in X]\n",
    "    \n",
    "    # Since there is no need to pad, we can assume all sequences are of equal length or\n",
    "    # handling variable length isn't required. We'll directly stack them into a single tensor.\n",
    "    # If sequences are of different lengths and you decide later to handle it, adjustments will be needed here.\n",
    "    X_tensor = torch.stack(X_tensors)\n",
    "    \n",
    "    # Convert list of single values into a torch tensor\n",
    "    y_tensor = torch.tensor(y, dtype=torch.float32).view(-1, 1)  # Reshape y to be a column vector\n",
    "    \n",
    "    # Create tensor dataset\n",
    "    dataset = TensorDataset(X_tensor, y_tensor)\n",
    "    \n",
    "    # Create data loader\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "def train_model(model, data_loader, criterion, optimizer, num_epochs, device):\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}\\n\")\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        num_samples = len(data_loader)\n",
    "\n",
    "        for i, (x_batch, y_batch) in enumerate(data_loader):\n",
    "            print(f\"\\rTraining: {int(100*i/num_samples)}%  \", end=\"\")\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # if (epoch + 1) % 10 == 0:\n",
    "        print(f'\\nEpoch [{epoch + 1}/{num_epochs}], Loss: {total_loss / len(data_loader):.4f}\\n')\n",
    "\n",
    "def test_model(model, data_loader, criterion, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():  # No gradients needed\n",
    "        for x_batch, y_batch in data_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(x_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    print(f'Test Loss: {total_loss / len(data_loader):.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5889/3849284745.py:258: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  'videos', 'comments', 'likes']].groupby('brand').apply(lambda x: x.iloc[:,1:].isna().sum()/len(x))\n",
      "/tmp/ipykernel_5889/3849284745.py:299: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  test_df = pd.concat([test_df, group.iloc[-n_test:]])\n",
      "/tmp/ipykernel_5889/3849284745.py:302: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_df = pd.concat([train_df, group.iloc[:-n_test]])\n",
      "/tmp/ipykernel_5889/3849284745.py:322: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train_df = train_df.groupby('brand').apply(lambda group: group.fillna(method='ffill'))\n",
      "/tmp/ipykernel_5889/3849284745.py:322: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  train_df = train_df.groupby('brand').apply(lambda group: group.fillna(method='ffill'))\n",
      "/tmp/ipykernel_5889/3849284745.py:325: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train_df = train_df.groupby('brand').apply(lambda group: group.fillna(method='bfill'))\n",
      "/tmp/ipykernel_5889/3849284745.py:325: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  train_df = train_df.groupby('brand').apply(lambda group: group.fillna(method='bfill'))\n",
      "/tmp/ipykernel_5889/3849284745.py:329: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  test_df = test_df.groupby('brand').apply(lambda group: group.fillna(method='ffill'))\n",
      "/tmp/ipykernel_5889/3849284745.py:329: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  test_df = test_df.groupby('brand').apply(lambda group: group.fillna(method='ffill'))\n",
      "/tmp/ipykernel_5889/3849284745.py:332: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  test_df = test_df.groupby('brand').apply(lambda group: group.fillna(method='bfill'))\n",
      "/tmp/ipykernel_5889/3849284745.py:332: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  test_df = test_df.groupby('brand').apply(lambda group: group.fillna(method='bfill'))\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH, sep=\";\")\n",
    "\n",
    "X_train, y_train, X_test, y_test = prepare_data_lstm(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "\n",
      "Training: 99%  \n",
      "Epoch [1/20], Loss: 0.9185\n",
      "\n",
      "\n",
      "Epoch 2\n",
      "\n",
      "Training: 99%  \n",
      "Epoch [2/20], Loss: 0.8510\n",
      "\n",
      "\n",
      "Epoch 3\n",
      "\n",
      "Training: 99%  \n",
      "Epoch [3/20], Loss: 0.8248\n",
      "\n",
      "\n",
      "Epoch 4\n",
      "\n",
      "Training: 99%  \n",
      "Epoch [4/20], Loss: 0.8002\n",
      "\n",
      "\n",
      "Epoch 5\n",
      "\n",
      "Training: 99%  \n",
      "Epoch [5/20], Loss: 0.7884\n",
      "\n",
      "\n",
      "Epoch 6\n",
      "\n",
      "Training: 99%  \n",
      "Epoch [6/20], Loss: 0.7779\n",
      "\n",
      "\n",
      "Epoch 7\n",
      "\n",
      "Training: 99%  \n",
      "Epoch [7/20], Loss: 0.7622\n",
      "\n",
      "\n",
      "Epoch 8\n",
      "\n",
      "Training: 99%  \n",
      "Epoch [8/20], Loss: 0.7620\n",
      "\n",
      "\n",
      "Epoch 9\n",
      "\n",
      "Training: 99%  \n",
      "Epoch [9/20], Loss: 0.7571\n",
      "\n",
      "\n",
      "Epoch 10\n",
      "\n",
      "Training: 99%  \n",
      "Epoch [10/20], Loss: 0.7512\n",
      "\n",
      "\n",
      "Epoch 11\n",
      "\n",
      "Training: 99%  \n",
      "Epoch [11/20], Loss: 0.7405\n",
      "\n",
      "\n",
      "Epoch 12\n",
      "\n",
      "Training: 99%  \n",
      "Epoch [12/20], Loss: 0.7329\n",
      "\n",
      "\n",
      "Epoch 13\n",
      "\n",
      "Training: 99%  \n",
      "Epoch [13/20], Loss: 0.7302\n",
      "\n",
      "\n",
      "Epoch 14\n",
      "\n",
      "Training: 99%  \n",
      "Epoch [14/20], Loss: 0.7243\n",
      "\n",
      "\n",
      "Epoch 15\n",
      "\n",
      "Training: 99%  \n",
      "Epoch [15/20], Loss: 0.7179\n",
      "\n",
      "\n",
      "Epoch 16\n",
      "\n",
      "Training: 99%  \n",
      "Epoch [16/20], Loss: 0.7531\n",
      "\n",
      "\n",
      "Epoch 17\n",
      "\n",
      "Training: 99%  \n",
      "Epoch [17/20], Loss: 0.7195\n",
      "\n",
      "\n",
      "Epoch 18\n",
      "\n",
      "Training: 99%  \n",
      "Epoch [18/20], Loss: 0.7079\n",
      "\n",
      "\n",
      "Epoch 19\n",
      "\n",
      "Training: 99%  \n",
      "Epoch [19/20], Loss: 0.7006\n",
      "\n",
      "\n",
      "Epoch 20\n",
      "\n",
      "Training: 99%  \n",
      "Epoch [20/20], Loss: 0.7133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hyperparameters\n",
    "input_size = X_train[0].shape[1]\n",
    "hidden_size = 64\n",
    "num_layers =2\n",
    "output_size = 1\n",
    "learning_rate = 0.001\n",
    "num_epochs = 20\n",
    "batch_size = 64\n",
    "\n",
    "# Model setup\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Initialize DataLoader\n",
    "data_loader = initialize_data_loader(X_train , y_train , batch_size)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, data_loader, criterion, optimizer, num_epochs, device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.7803\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize DataLoader for test data\n",
    "test_data_loader = initialize_data_loader(X_test, y_test, batch_size)\n",
    "\n",
    "\n",
    "test_model(model, data_loader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-11 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-11 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-11 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-11 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-11 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-11 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-11 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-11 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-11 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-11 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "X_train_reg = [x[-1] for x in X_train]\n",
    "\n",
    "model.fit(X_train_reg, y_train)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_test_reg = [x[-1] for x in X_test]\n",
    "\n",
    "y_hat = model.predict(X_test_reg)\n",
    "\n",
    "mean_squared_error(y_hat, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datathon24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
