{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations\n",
    "\n",
    "- period and calculation_type features all the same value, can drop\n",
    "- split time series into batches of shorter sequences\n",
    "- how to impute intermediate missing values? -> take last? interpolate?\n",
    "- add year, month, absolute int as features for date\n",
    "\n",
    "- one hot encoding of categorical features: too many, not important enough... drop? keep as single numerical feature?\n",
    "\n",
    "- duplicate datapoints, same brand, same date, same values - two different compsets...\n",
    "\n",
    "# TODO:\n",
    "- align the data by brand\n",
    "- are there weeks missing in between?\n",
    "- normalize values\n",
    "\n",
    "\n",
    "# Discussion\n",
    "- should we predict by brand or by legal entity?\n",
    "\n",
    "\n",
    "- standardization in the end after adding additional metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/david/code/datathon24-personal/data/skylab_instagram_datathon_dataset.csv\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH, sep=\";\")\n",
    "\n",
    "\n",
    "def video_to_picture_ratio(df, videos_col, pictures_col):\n",
    "    df['video_picture_ratio'] = df[videos_col] / df[pictures_col]\n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_rolling_average_per_brand(data, brand_column, window_size=7):\n",
    "    \"\"\"\n",
    "    Calculate the rolling average of 'engagement' for each brand in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        data (pd.DataFrame): The DataFrame containing the data.\n",
    "        brand_column (str): The column name which identifies the brand.\n",
    "        window_size (int): The number of observations used for calculating the rolling average.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with a new column for the rolling average of 'engagement' calculated per brand.\n",
    "    \"\"\"\n",
    "    # Group by brand and calculate rolling average within each group\n",
    "    data['rolling_avg_engagement'] = data.groupby(brand_column)['engagement'].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
    "    return data\n",
    "\n",
    "\n",
    "def calculate_exponential_moving_average_per_brand(data, brand_column, span=7):\n",
    "    \"\"\"\n",
    "    Calculate the exponential moving average of 'engagement' for each brand in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        data (pd.DataFrame): The DataFrame containing the data.\n",
    "        brand_column (str): The column name which identifies the brand.\n",
    "        span (int): The decay in terms of the span of the exponential window.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with a new column for the exponential moving average of 'engagement' calculated per brand.\n",
    "    \"\"\"\n",
    "    # Group by brand and calculate EMA within each group\n",
    "    data['ewma_engagement'] = data.groupby(brand_column)['engagement'].transform(lambda x: x.ewm(span=span, adjust=False).mean())\n",
    "    return data\n",
    "\n",
    "\n",
    "def calculate_brand_wise_growth_rates(data, column_names, brand_column):\n",
    "    \"\"\"\n",
    "    Calculate the growth rate for specified columns in a DataFrame, grouped by brand.\n",
    "    Replace NaN values with 0 where growth rate cannot be calculated.\n",
    "\n",
    "    Parameters:\n",
    "        data (pd.DataFrame): The DataFrame containing the data.\n",
    "        column_names (list of str): A list of column names to calculate the growth rate.\n",
    "        brand_column (str): The column name which identifies the brand.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with new columns for each specified column's growth rate, calculated for each brand and NaN replaced by 0.\n",
    "    \"\"\"\n",
    "    for column in column_names:\n",
    "        # Calculate growth rate within each brand group\n",
    "        data[f'growth_rate_{column}'] = data.groupby(brand_column)[column].pct_change() * 100\n",
    "        # Replace NaN values with 0\n",
    "        data[f'growth_rate_{column}'].fillna(0, inplace=True)\n",
    "    return data\n",
    "\n",
    "def calculate_brand_rolling_statistics(data, column_name, brand_column, window_size=7):\n",
    "    \"\"\"\n",
    "    Calculate rolling statistics for a specified column in a DataFrame, grouped by brand,\n",
    "    and replace NaN values with 0.\n",
    "\n",
    "    Parameters:\n",
    "        data (pd.DataFrame): The DataFrame containing the data.\n",
    "        column_name (str): The column name to calculate rolling statistics.\n",
    "        brand_column (str): The column name which identifies the brand.\n",
    "        window_size (int): The number of observations used for calculating the rolling statistic.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with new columns for each rolling statistic of the specified column, calculated for each brand.\n",
    "    \"\"\"\n",
    "    grouped = data.groupby(brand_column)[column_name]\n",
    "    data[f'{column_name}_rolling_min'] = grouped.transform(lambda x: x.rolling(window=window_size, min_periods=1).min()).fillna(0)\n",
    "    data[f'{column_name}_rolling_max'] = grouped.transform(lambda x: x.rolling(window=window_size, min_periods=1).max()).fillna(0)\n",
    "    data[f'{column_name}_rolling_std'] = grouped.transform(lambda x: x.rolling(window=window_size, min_periods=1).std()).fillna(0)\n",
    "\n",
    "    return data\n",
    "\n",
    "def create_brand_lag_features(data, column_name, brand_column, lag_periods):\n",
    "    \"\"\"\n",
    "    Create lag features for a specified column in a DataFrame, grouped by brand,\n",
    "    and replace NaN values with 0.\n",
    "\n",
    "    Parameters:\n",
    "        data (pd.DataFrame): The DataFrame containing the data.\n",
    "        column_name (str): The column name to create lag features for.\n",
    "        brand_column (str): The column name which identifies the brand.\n",
    "        lag_periods (int): The number of lag periods.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with new columns for each lag feature of the specified column, calculated for each brand.\n",
    "    \"\"\"\n",
    "    for i in range(1, lag_periods + 1):\n",
    "        data[f'{column_name}_lag_{i}'] = data.groupby(brand_column)[column_name].shift(i).fillna(0)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def preprocess_data(df, missing_values_cutoff=0.7, test_fraction=0.2):\n",
    "\n",
    "    df = df.drop(columns=[\"period\", \"calculation_type\", \"compset\", \"compset_group\", \"legal_entity_name\", \"ultimate_parent_legal_entity_name\", \"primary_exchange_name\"])\n",
    "    df[\"period_end_date\"] = pd.to_datetime(df[\"period_end_date\"])\n",
    "\n",
    "    df = df.rename(columns={'business_entity_doing_business_as_name': 'brand', 'period_end_date': 'date'})\n",
    "\n",
    "    df = df[df['brand'] != \"All Brands\"]\n",
    "    df = df[df['brand'] != \"Boca\"]\n",
    "\n",
    "    df = df.groupby(['brand', 'date']).first().reset_index()\n",
    "\n",
    "    def correct_country_name(name):\n",
    "        country_map = {\n",
    "            \"Hong Kong\": \"China\",\n",
    "            \"China;Hong Kong\": \"China\",\n",
    "            \";France\": \"France\",\n",
    "            \";\": None,\n",
    "            \"Belgium;\": \"Belgium\"\n",
    "        }\n",
    "        if name in country_map.keys():\n",
    "            return country_map[name]\n",
    "        return name\n",
    "\n",
    "    df['domicile_country_name'] = df['domicile_country_name'].apply(correct_country_name)\n",
    "\n",
    "\n",
    "    categorical_features = [\"domicile_country_name\"]\n",
    "    for feature in categorical_features:\n",
    "        df = pd.get_dummies(df, columns=[feature], prefix=feature, dummy_na=True, dtype=int)\n",
    "\n",
    "    # TODO: remove bad data\n",
    "    na_frac = df[['brand', 'followers', 'pictures',\n",
    "        'videos', 'comments', 'likes']].groupby('brand').apply(lambda x: x.iloc[:,1:].isna().sum()/len(x))\n",
    "\n",
    "    bad_brands = list(na_frac[na_frac.max(axis=1) > missing_values_cutoff].index)\n",
    "\n",
    "    df = df[~df['brand'].isin(bad_brands)]\n",
    "\n",
    "\n",
    "    # TODO: add additional features\n",
    "    df['engagement'] = df['comments'] + df['likes']\n",
    "    df['engagement_rate'] = df['engagement']/df['followers']\n",
    "    df['engagement_rate_per_post'] =  df['engagement_rate']/(df['videos'] + df['pictures'])\n",
    "\n",
    "\n",
    "    # df = video_to_picture_ratio(df, \"videos\", \"pictures\")\n",
    "    df = calculate_rolling_average_per_brand(df, \"brand\", window_size=4)\n",
    "    df = calculate_exponential_moving_average_per_brand(df, \"brand\", span=4)\n",
    "    # df = calculate_brand_wise_growth_rates(df, [\"comments\", \"likes\", \"followers\", \"pictures\", \"videos\"], \"brand\")\n",
    "    for c in [\"comments\", \"likes\", \"followers\", \"pictures\", \"videos\"]:\n",
    "        df = calculate_brand_rolling_statistics(df, c, \"brand\", window_size=4)\n",
    "        df = create_brand_lag_features(df, c, \"brand\", 4)\n",
    "\n",
    "    \n",
    "    # Step 1: Sort the dataframe by time\n",
    "    df_sorted = df.sort_values(by='date')\n",
    "\n",
    "    # Step 2: Group the dataframe by 'Brand'\n",
    "    grouped = df_sorted.groupby('brand')\n",
    "\n",
    "    # Step 3: Define an empty dataframe for train and test sets\n",
    "    train_df = pd.DataFrame(columns=df.columns)  # Columns same as original dataframe\n",
    "    test_df = pd.DataFrame(columns=df.columns)   # Columns same as original dataframe\n",
    "\n",
    "    # Step 4: Iterate over each group and split into train and test sets\n",
    "    for _, group in grouped:\n",
    "        n_rows = len(group)\n",
    "        n_test = int(test_fraction * n_rows)  # 20% of rows for test set\n",
    "\n",
    "        # Add last 20% of rows to test set\n",
    "        test_df = pd.concat([test_df, group.iloc[-n_test:]])\n",
    "\n",
    "        # Add remaining rows to train set\n",
    "        train_df = pd.concat([train_df, group.iloc[:-n_test]])\n",
    "\n",
    "    # Step 5: Reset index for both train and test dataframes\n",
    "    train_df.reset_index(drop=True, inplace=True)\n",
    "    test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "    # TODO: normalize values\n",
    "\n",
    "    normalize_cols = [c for c in train_df.columns if c not in ['brand', 'date'] and not c.startswith(\"domicile_country_name\")]\n",
    "    for col in normalize_cols:\n",
    "        m = train_df[col].mean()\n",
    "        s = train_df[col].std()\n",
    "        train_df[col] = (train_df[col] - m)/s\n",
    "        test_df[col] = (test_df[col] - m)/s\n",
    "\n",
    "\n",
    "    # TODO: impute missing values\n",
    "  \n",
    "    # TODO: impute missing values\n",
    "    train_df = train_df.groupby('brand').apply(lambda group: group.fillna(method='ffill'))\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "    train_df = train_df.groupby('brand').apply(lambda group: group.fillna(method='bfill'))\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "    test_df = test_df.groupby('brand').apply(lambda group: group.fillna(method='ffill'))\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "    test_df = test_df.groupby('brand').apply(lambda group: group.fillna(method='bfill'))\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "def prepare_data_lstm(df, sequence_length=10, prediction_dist=4, missing_values_cutoff=0.7, test_fraction=0.2):\n",
    "\n",
    "    df = df.drop(columns=[\"period\", \"calculation_type\", \"compset\", \"compset_group\", \"legal_entity_name\", \"ultimate_parent_legal_entity_name\", \"primary_exchange_name\"])\n",
    "    df[\"period_end_date\"] = pd.to_datetime(df[\"period_end_date\"])\n",
    "\n",
    "    df = df.rename(columns={'business_entity_doing_business_as_name': 'brand', 'period_end_date': 'date'})\n",
    "\n",
    "    df = df[df['brand'] != \"All Brands\"]\n",
    "    df = df[df['brand'] != \"Boca\"]\n",
    "\n",
    "    df = df.groupby(['brand', 'date']).first().reset_index()\n",
    "\n",
    "    def correct_country_name(name):\n",
    "        country_map = {\n",
    "            \"Hong Kong\": \"China\",\n",
    "            \"China;Hong Kong\": \"China\",\n",
    "            \";France\": \"France\",\n",
    "            \";\": None,\n",
    "            \"Belgium;\": \"Belgium\"\n",
    "        }\n",
    "        if name in country_map.keys():\n",
    "            return country_map[name]\n",
    "        return name\n",
    "\n",
    "    df['domicile_country_name'] = df['domicile_country_name'].apply(correct_country_name)\n",
    "\n",
    "\n",
    "    categorical_features = [\"domicile_country_name\"]\n",
    "    for feature in categorical_features:\n",
    "        df = pd.get_dummies(df, columns=[feature], prefix=feature, dummy_na=True, dtype=int)\n",
    "\n",
    "    # TODO: remove bad data\n",
    "    na_frac = df[['brand', 'followers', 'pictures',\n",
    "        'videos', 'comments', 'likes']].groupby('brand').apply(lambda x: x.iloc[:,1:].isna().sum()/len(x))\n",
    "\n",
    "    bad_brands = list(na_frac[na_frac.max(axis=1) > missing_values_cutoff].index)\n",
    "\n",
    "    df = df[~df['brand'].isin(bad_brands)]\n",
    "\n",
    "\n",
    "    # TODO: add additional features\n",
    "    df['engagement'] = df['comments'] + df['likes']\n",
    "    df['engagement_rate'] = df['engagement']/df['followers']\n",
    "    df['engagement_rate_per_post'] =  df['engagement_rate']/(df['videos'] + df['pictures'])\n",
    "\n",
    "\n",
    "    # df = video_to_picture_ratio(df, \"videos\", \"pictures\")\n",
    "    df = calculate_rolling_average_per_brand(df, \"brand\", window_size=4)\n",
    "    df = calculate_exponential_moving_average_per_brand(df, \"brand\", span=4)\n",
    "    # df = calculate_brand_wise_growth_rates(df, [\"comments\", \"likes\", \"followers\", \"pictures\", \"videos\"], \"brand\")\n",
    "    for c in [\"comments\", \"likes\", \"followers\", \"pictures\", \"videos\"]:\n",
    "        df = calculate_brand_rolling_statistics(df, c, \"brand\", window_size=4)\n",
    "        df = create_brand_lag_features(df, c, \"brand\", 4)\n",
    "\n",
    "\n",
    "\n",
    "    # Step 1: Sort the dataframe by time\n",
    "    df_sorted = df.sort_values(by='date')\n",
    "\n",
    "    # Step 2: Group the dataframe by 'Brand'\n",
    "    grouped = df_sorted.groupby('brand')\n",
    "\n",
    "    # Step 3: Define an empty dataframe for train and test sets\n",
    "    train_df = pd.DataFrame(columns=df.columns)  # Columns same as original dataframe\n",
    "    test_df = pd.DataFrame(columns=df.columns)   # Columns same as original dataframe\n",
    "\n",
    "    # Step 4: Iterate over each group and split into train and test sets\n",
    "    for _, group in grouped:\n",
    "        n_rows = len(group)\n",
    "        n_test = int(test_fraction * n_rows)  # 20% of rows for test set\n",
    "\n",
    "        # Add last 20% of rows to test set\n",
    "        test_df = pd.concat([test_df, group.iloc[-n_test:]])\n",
    "\n",
    "        # Add remaining rows to train set\n",
    "        train_df = pd.concat([train_df, group.iloc[:-n_test]])\n",
    "\n",
    "    # Step 5: Reset index for both train and test dataframes\n",
    "    train_df.reset_index(drop=True, inplace=True)\n",
    "    test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "    # TODO: normalize values\n",
    "\n",
    "    normalize_cols = [c for c in train_df.columns if c not in ['brand', 'date'] and not c.startswith(\"domicile_country_name\")]\n",
    "    for col in normalize_cols:\n",
    "        m = train_df[col].mean()\n",
    "        s = train_df[col].std()\n",
    "        train_df[col] = (train_df[col] - m)/s\n",
    "        test_df[col] = (test_df[col] - m)/s\n",
    "\n",
    "\n",
    "    # TODO: impute missing values\n",
    "  \n",
    "    # TODO: impute missing values\n",
    "    train_df = train_df.groupby('brand').apply(lambda group: group.fillna(method='ffill'))\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "    train_df = train_df.groupby('brand').apply(lambda group: group.fillna(method='bfill'))\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "    test_df = test_df.groupby('brand').apply(lambda group: group.fillna(method='ffill'))\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "    test_df = test_df.groupby('brand').apply(lambda group: group.fillna(method='bfill'))\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "    # TODO: create sequences\n",
    "\n",
    "    # TODO: split df into brands\n",
    "    # sequence per brand\n",
    "    # label\n",
    "\n",
    "    label_col = \"engagement_rate_per_post\"\n",
    "\n",
    "    train_sequences = []\n",
    "    train_labels = []\n",
    "    test_sequences = []\n",
    "    test_labels = []\n",
    "\n",
    "\n",
    "    for bi, brand in enumerate(df['brand'].unique()):\n",
    "\n",
    "        brand_train_df = train_df[train_df['brand'] == brand]\n",
    "\n",
    "        cols = [c for c in train_df.columns if (c != \"brand\" and c != \"date\")]\n",
    "        brand_train_df = brand_train_df[cols]\n",
    "\n",
    "        for i in range(len(brand_train_df) - (sequence_length + prediction_dist)):\n",
    "            sequence = brand_train_df.iloc[i:i + sequence_length].values\n",
    "            train_sequences.append(sequence)\n",
    "\n",
    "            sequence_labels = brand_train_df.iloc[i+sequence_length+prediction_dist][label_col]\n",
    "            train_labels.append(sequence_labels)\n",
    "        \n",
    "        brand_test_df = test_df[test_df['brand'] == brand]\n",
    "\n",
    "        brand_test_df = brand_test_df[cols]\n",
    "\n",
    "\n",
    "        for i in range(len(brand_test_df) - (sequence_length + prediction_dist)):\n",
    "            sequence = brand_test_df.iloc[i:i + sequence_length].values\n",
    "            test_sequences.append(sequence)\n",
    "\n",
    "            sequence_labels = brand_test_df.iloc[i+sequence_length+prediction_dist][label_col]\n",
    "            test_labels.append(sequence_labels)\n",
    "\n",
    "\n",
    "    return train_sequences, train_labels, test_sequences, test_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5459/3562934620.py:251: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  'videos', 'comments', 'likes']].groupby('brand').apply(lambda x: x.iloc[:,1:].isna().sum()/len(x))\n",
      "/tmp/ipykernel_5459/3562934620.py:60: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  data[f'growth_rate_{column}'] = data.groupby(brand_column)[column].pct_change() * 100\n",
      "/tmp/ipykernel_5459/3562934620.py:62: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[f'growth_rate_{column}'].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_5459/3562934620.py:60: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  data[f'growth_rate_{column}'] = data.groupby(brand_column)[column].pct_change() * 100\n",
      "/tmp/ipykernel_5459/3562934620.py:62: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[f'growth_rate_{column}'].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_5459/3562934620.py:60: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  data[f'growth_rate_{column}'] = data.groupby(brand_column)[column].pct_change() * 100\n",
      "/tmp/ipykernel_5459/3562934620.py:62: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[f'growth_rate_{column}'].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_5459/3562934620.py:60: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  data[f'growth_rate_{column}'] = data.groupby(brand_column)[column].pct_change() * 100\n",
      "/tmp/ipykernel_5459/3562934620.py:62: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[f'growth_rate_{column}'].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_5459/3562934620.py:60: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  data[f'growth_rate_{column}'] = data.groupby(brand_column)[column].pct_change() * 100\n",
      "/tmp/ipykernel_5459/3562934620.py:62: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[f'growth_rate_{column}'].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_5459/3562934620.py:290: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  test_df = pd.concat([test_df, group.iloc[-n_test:]])\n",
      "/tmp/ipykernel_5459/3562934620.py:293: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_df = pd.concat([train_df, group.iloc[:-n_test]])\n",
      "/home/david/anaconda3/envs/datathon24/lib/python3.11/site-packages/pandas/core/nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n",
      "/tmp/ipykernel_5459/3562934620.py:313: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train_df = train_df.groupby('brand').apply(lambda group: group.fillna(method='ffill'))\n",
      "/tmp/ipykernel_5459/3562934620.py:313: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_df = train_df.groupby('brand').apply(lambda group: group.fillna(method='ffill'))\n",
      "/tmp/ipykernel_5459/3562934620.py:313: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  train_df = train_df.groupby('brand').apply(lambda group: group.fillna(method='ffill'))\n",
      "/tmp/ipykernel_5459/3562934620.py:316: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train_df = train_df.groupby('brand').apply(lambda group: group.fillna(method='bfill'))\n",
      "/tmp/ipykernel_5459/3562934620.py:316: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  train_df = train_df.groupby('brand').apply(lambda group: group.fillna(method='bfill'))\n",
      "/tmp/ipykernel_5459/3562934620.py:320: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  test_df = test_df.groupby('brand').apply(lambda group: group.fillna(method='ffill'))\n",
      "/tmp/ipykernel_5459/3562934620.py:320: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_df = test_df.groupby('brand').apply(lambda group: group.fillna(method='ffill'))\n",
      "/tmp/ipykernel_5459/3562934620.py:320: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  test_df = test_df.groupby('brand').apply(lambda group: group.fillna(method='ffill'))\n",
      "/tmp/ipykernel_5459/3562934620.py:323: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  test_df = test_df.groupby('brand').apply(lambda group: group.fillna(method='bfill'))\n",
      "/tmp/ipykernel_5459/3562934620.py:323: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  test_df = test_df.groupby('brand').apply(lambda group: group.fillna(method='bfill'))\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = prepare_data_lstm(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5459/3562934620.py:139: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  'videos', 'comments', 'likes']].groupby('brand').apply(lambda x: x.iloc[:,1:].isna().sum()/len(x))\n",
      "/tmp/ipykernel_5459/3562934620.py:60: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  data[f'growth_rate_{column}'] = data.groupby(brand_column)[column].pct_change() * 100\n",
      "/tmp/ipykernel_5459/3562934620.py:62: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[f'growth_rate_{column}'].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_5459/3562934620.py:60: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  data[f'growth_rate_{column}'] = data.groupby(brand_column)[column].pct_change() * 100\n",
      "/tmp/ipykernel_5459/3562934620.py:62: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[f'growth_rate_{column}'].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_5459/3562934620.py:60: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  data[f'growth_rate_{column}'] = data.groupby(brand_column)[column].pct_change() * 100\n",
      "/tmp/ipykernel_5459/3562934620.py:62: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[f'growth_rate_{column}'].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_5459/3562934620.py:60: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  data[f'growth_rate_{column}'] = data.groupby(brand_column)[column].pct_change() * 100\n",
      "/tmp/ipykernel_5459/3562934620.py:62: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[f'growth_rate_{column}'].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_5459/3562934620.py:60: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  data[f'growth_rate_{column}'] = data.groupby(brand_column)[column].pct_change() * 100\n",
      "/tmp/ipykernel_5459/3562934620.py:62: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[f'growth_rate_{column}'].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_5459/3562934620.py:177: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  test_df = pd.concat([test_df, group.iloc[-n_test:]])\n",
      "/tmp/ipykernel_5459/3562934620.py:180: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_df = pd.concat([train_df, group.iloc[:-n_test]])\n",
      "/home/david/anaconda3/envs/datathon24/lib/python3.11/site-packages/pandas/core/nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n",
      "/tmp/ipykernel_5459/3562934620.py:200: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train_df = train_df.groupby('brand').apply(lambda group: group.fillna(method='ffill'))\n",
      "/tmp/ipykernel_5459/3562934620.py:200: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_df = train_df.groupby('brand').apply(lambda group: group.fillna(method='ffill'))\n",
      "/tmp/ipykernel_5459/3562934620.py:200: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  train_df = train_df.groupby('brand').apply(lambda group: group.fillna(method='ffill'))\n",
      "/tmp/ipykernel_5459/3562934620.py:203: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train_df = train_df.groupby('brand').apply(lambda group: group.fillna(method='bfill'))\n",
      "/tmp/ipykernel_5459/3562934620.py:203: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  train_df = train_df.groupby('brand').apply(lambda group: group.fillna(method='bfill'))\n",
      "/tmp/ipykernel_5459/3562934620.py:207: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  test_df = test_df.groupby('brand').apply(lambda group: group.fillna(method='ffill'))\n",
      "/tmp/ipykernel_5459/3562934620.py:207: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_df = test_df.groupby('brand').apply(lambda group: group.fillna(method='ffill'))\n",
      "/tmp/ipykernel_5459/3562934620.py:207: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  test_df = test_df.groupby('brand').apply(lambda group: group.fillna(method='ffill'))\n",
      "/tmp/ipykernel_5459/3562934620.py:210: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  test_df = test_df.groupby('brand').apply(lambda group: group.fillna(method='bfill'))\n",
      "/tmp/ipykernel_5459/3562934620.py:210: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  test_df = test_df.groupby('brand').apply(lambda group: group.fillna(method='bfill'))\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH, sep=\";\")\n",
    "train, test = preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brand 0\n",
      "date 0\n",
      "followers 0\n",
      "pictures 0\n",
      "videos 0\n",
      "comments 0\n",
      "likes 0\n",
      "domicile_country_name_Australia 0\n",
      "domicile_country_name_Belgium 0\n",
      "domicile_country_name_Brazil 0\n",
      "domicile_country_name_Canada 0\n",
      "domicile_country_name_China 0\n",
      "domicile_country_name_Denmark 0\n",
      "domicile_country_name_France 0\n",
      "domicile_country_name_Germany 0\n",
      "domicile_country_name_Italy 0\n",
      "domicile_country_name_Japan 0\n",
      "domicile_country_name_Mexico 0\n",
      "domicile_country_name_Netherlands 0\n",
      "domicile_country_name_New Zealand 0\n",
      "domicile_country_name_Philippines 0\n",
      "domicile_country_name_Poland 0\n",
      "domicile_country_name_Singapore 0\n",
      "domicile_country_name_Spain 0\n",
      "domicile_country_name_Sweden 0\n",
      "domicile_country_name_Switzerland 0\n",
      "domicile_country_name_United Kingdom of Great Britain and Northern Ireland 0\n",
      "domicile_country_name_United States of America 0\n",
      "domicile_country_name_nan 0\n",
      "engagement 0\n",
      "engagement_rate 0\n",
      "engagement_rate_per_post 0\n",
      "video_picture_ratio 231935\n",
      "rolling_avg_engagement 0\n",
      "ewma_engagement 0\n",
      "growth_rate_comments 231935\n",
      "growth_rate_likes 231935\n",
      "growth_rate_followers 0\n",
      "growth_rate_pictures 231935\n",
      "growth_rate_videos 231935\n",
      "comments_rolling_min 0\n",
      "comments_rolling_max 0\n",
      "comments_rolling_std 0\n",
      "comments_lag_1 0\n",
      "comments_lag_2 0\n",
      "comments_lag_3 0\n",
      "comments_lag_4 0\n",
      "likes_rolling_min 0\n",
      "likes_rolling_max 0\n",
      "likes_rolling_std 0\n",
      "likes_lag_1 0\n",
      "likes_lag_2 0\n",
      "likes_lag_3 0\n",
      "likes_lag_4 0\n",
      "followers_rolling_min 0\n",
      "followers_rolling_max 0\n",
      "followers_rolling_std 0\n",
      "followers_lag_1 0\n",
      "followers_lag_2 0\n",
      "followers_lag_3 0\n",
      "followers_lag_4 0\n",
      "pictures_rolling_min 0\n",
      "pictures_rolling_max 0\n",
      "pictures_rolling_std 0\n",
      "pictures_lag_1 0\n",
      "pictures_lag_2 0\n",
      "pictures_lag_3 0\n",
      "pictures_lag_4 0\n",
      "videos_rolling_min 0\n",
      "videos_rolling_max 0\n",
      "videos_rolling_std 0\n",
      "videos_lag_1 0\n",
      "videos_lag_2 0\n",
      "videos_lag_3 0\n",
      "videos_lag_4 0\n"
     ]
    }
   ],
   "source": [
    "for k, v in train.isna().sum().items():\n",
    "    print(k, v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datathon24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
