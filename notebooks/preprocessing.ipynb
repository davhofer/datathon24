{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations\n",
    "\n",
    "- period and calculation_type features all the same value, can drop\n",
    "- split time series into batches of shorter sequences\n",
    "- how to impute intermediate missing values? -> take last? interpolate?\n",
    "- add year, month, absolute int as features for date\n",
    "\n",
    "- one hot encoding of categorical features: too many, not important enough... drop? keep as single numerical feature?\n",
    "\n",
    "- duplicate datapoints, same brand, same date, same values - two different compsets...\n",
    "\n",
    "# TODO:\n",
    "- align the data by brand\n",
    "- are there weeks missing in between?\n",
    "- normalize values\n",
    "\n",
    "\n",
    "# Discussion\n",
    "- should we predict by brand or by legal entity?\n",
    "\n",
    "\n",
    "- standardization in the end after adding additional metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH, sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['business_entity_doing_business_as_name'] != 'All Brands']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "430176998.0"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['followers'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>period_end_date</th>\n",
       "      <th>compset_group</th>\n",
       "      <th>compset</th>\n",
       "      <th>business_entity_doing_business_as_name</th>\n",
       "      <th>legal_entity_name</th>\n",
       "      <th>domicile_country_name</th>\n",
       "      <th>ultimate_parent_legal_entity_name</th>\n",
       "      <th>primary_exchange_name</th>\n",
       "      <th>calculation_type</th>\n",
       "      <th>followers</th>\n",
       "      <th>pictures</th>\n",
       "      <th>videos</th>\n",
       "      <th>comments</th>\n",
       "      <th>likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>499780</th>\n",
       "      <td>Weekly</td>\n",
       "      <td>2023-09-16</td>\n",
       "      <td>Sportswear &amp; Athleisure</td>\n",
       "      <td>Sportswear</td>\n",
       "      <td>Nike</td>\n",
       "      <td>Nike</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Nike</td>\n",
       "      <td>New York Stock Exchange</td>\n",
       "      <td>Metric Value</td>\n",
       "      <td>430176998.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>42514.0</td>\n",
       "      <td>9194724.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499961</th>\n",
       "      <td>Weekly</td>\n",
       "      <td>2023-09-16</td>\n",
       "      <td>Sportswear &amp; Athleisure</td>\n",
       "      <td>US Softlines Analyst Interest List</td>\n",
       "      <td>Nike</td>\n",
       "      <td>Nike</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Nike</td>\n",
       "      <td>New York Stock Exchange</td>\n",
       "      <td>Metric Value</td>\n",
       "      <td>430176998.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>42514.0</td>\n",
       "      <td>9194724.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500042</th>\n",
       "      <td>Weekly</td>\n",
       "      <td>2023-09-16</td>\n",
       "      <td>Sportswear &amp; Athleisure</td>\n",
       "      <td>Sportswear &amp; Athleisure</td>\n",
       "      <td>Nike</td>\n",
       "      <td>Nike</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Nike</td>\n",
       "      <td>New York Stock Exchange</td>\n",
       "      <td>Metric Value</td>\n",
       "      <td>430176998.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>42514.0</td>\n",
       "      <td>9194724.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        period period_end_date            compset_group  \\\n",
       "499780  Weekly      2023-09-16  Sportswear & Athleisure   \n",
       "499961  Weekly      2023-09-16  Sportswear & Athleisure   \n",
       "500042  Weekly      2023-09-16  Sportswear & Athleisure   \n",
       "\n",
       "                                   compset  \\\n",
       "499780                          Sportswear   \n",
       "499961  US Softlines Analyst Interest List   \n",
       "500042             Sportswear & Athleisure   \n",
       "\n",
       "       business_entity_doing_business_as_name legal_entity_name  \\\n",
       "499780                                   Nike              Nike   \n",
       "499961                                   Nike              Nike   \n",
       "500042                                   Nike              Nike   \n",
       "\n",
       "           domicile_country_name ultimate_parent_legal_entity_name  \\\n",
       "499780  United States of America                              Nike   \n",
       "499961  United States of America                              Nike   \n",
       "500042  United States of America                              Nike   \n",
       "\n",
       "          primary_exchange_name calculation_type    followers  pictures  \\\n",
       "499780  New York Stock Exchange     Metric Value  430176998.0     196.0   \n",
       "499961  New York Stock Exchange     Metric Value  430176998.0     196.0   \n",
       "500042  New York Stock Exchange     Metric Value  430176998.0     196.0   \n",
       "\n",
       "        videos  comments      likes  \n",
       "499780   139.0   42514.0  9194724.0  \n",
       "499961   139.0   42514.0  9194724.0  \n",
       "500042   139.0   42514.0  9194724.0  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['followers'] == 430176998.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>period_end_date</th>\n",
       "      <th>compset_group</th>\n",
       "      <th>compset</th>\n",
       "      <th>business_entity_doing_business_as_name</th>\n",
       "      <th>legal_entity_name</th>\n",
       "      <th>domicile_country_name</th>\n",
       "      <th>ultimate_parent_legal_entity_name</th>\n",
       "      <th>primary_exchange_name</th>\n",
       "      <th>calculation_type</th>\n",
       "      <th>followers</th>\n",
       "      <th>pictures</th>\n",
       "      <th>videos</th>\n",
       "      <th>comments</th>\n",
       "      <th>likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68827</th>\n",
       "      <td>Weekly</td>\n",
       "      <td>2016-08-27</td>\n",
       "      <td>Luxury &amp; Premium &amp; Mainstream</td>\n",
       "      <td>Footwear</td>\n",
       "      <td>Nine West</td>\n",
       "      <td>Premier Brands</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sycamore Partners</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metric Value</td>\n",
       "      <td>NaN</td>\n",
       "      <td>282.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3154.0</td>\n",
       "      <td>162063.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68828</th>\n",
       "      <td>Weekly</td>\n",
       "      <td>2016-03-19</td>\n",
       "      <td>Luxury &amp; Premium &amp; Mainstream</td>\n",
       "      <td>Luxury &amp; Premium &amp; Mainstream</td>\n",
       "      <td>Nine West</td>\n",
       "      <td>Premier Brands</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sycamore Partners</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metric Value</td>\n",
       "      <td>NaN</td>\n",
       "      <td>278.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4547.0</td>\n",
       "      <td>123483.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68829</th>\n",
       "      <td>Weekly</td>\n",
       "      <td>2023-08-26</td>\n",
       "      <td>Luxury &amp; Premium &amp; Mainstream</td>\n",
       "      <td>US Softlines Analyst Interest List</td>\n",
       "      <td>Nine West</td>\n",
       "      <td>Premier Brands</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sycamore Partners</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metric Value</td>\n",
       "      <td>1966375.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4235.0</td>\n",
       "      <td>17044.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68830</th>\n",
       "      <td>Weekly</td>\n",
       "      <td>2018-11-03</td>\n",
       "      <td>Luxury &amp; Premium &amp; Mainstream</td>\n",
       "      <td>Footwear</td>\n",
       "      <td>Nine West</td>\n",
       "      <td>Premier Brands</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sycamore Partners</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metric Value</td>\n",
       "      <td>1101163.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5819.0</td>\n",
       "      <td>197415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68831</th>\n",
       "      <td>Weekly</td>\n",
       "      <td>2019-03-16</td>\n",
       "      <td>Luxury &amp; Premium &amp; Mainstream</td>\n",
       "      <td>Luxury &amp; Premium &amp; Mainstream</td>\n",
       "      <td>Nine West</td>\n",
       "      <td>Premier Brands</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sycamore Partners</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metric Value</td>\n",
       "      <td>1196891.0</td>\n",
       "      <td>382.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5812.0</td>\n",
       "      <td>237443.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70187</th>\n",
       "      <td>Weekly</td>\n",
       "      <td>2023-07-29</td>\n",
       "      <td>Luxury &amp; Premium &amp; Mainstream</td>\n",
       "      <td>US Softlines Analyst Interest List</td>\n",
       "      <td>Nine West</td>\n",
       "      <td>Premier Brands</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sycamore Partners</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metric Value</td>\n",
       "      <td>1963930.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3148.0</td>\n",
       "      <td>21942.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70188</th>\n",
       "      <td>Weekly</td>\n",
       "      <td>2023-06-24</td>\n",
       "      <td>Luxury &amp; Premium &amp; Mainstream</td>\n",
       "      <td>US Softlines Analyst Interest List</td>\n",
       "      <td>Nine West</td>\n",
       "      <td>Premier Brands</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sycamore Partners</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metric Value</td>\n",
       "      <td>1961784.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>37852.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70189</th>\n",
       "      <td>Weekly</td>\n",
       "      <td>2019-12-07</td>\n",
       "      <td>Luxury &amp; Premium &amp; Mainstream</td>\n",
       "      <td>US Softlines Analyst Interest List</td>\n",
       "      <td>Nine West</td>\n",
       "      <td>Premier Brands</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sycamore Partners</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metric Value</td>\n",
       "      <td>1456414.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4015.0</td>\n",
       "      <td>171113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70190</th>\n",
       "      <td>Weekly</td>\n",
       "      <td>2018-03-24</td>\n",
       "      <td>Luxury &amp; Premium &amp; Mainstream</td>\n",
       "      <td>Footwear</td>\n",
       "      <td>Nine West</td>\n",
       "      <td>Premier Brands</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sycamore Partners</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metric Value</td>\n",
       "      <td>955823.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4481.0</td>\n",
       "      <td>174004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70191</th>\n",
       "      <td>Weekly</td>\n",
       "      <td>2023-09-02</td>\n",
       "      <td>Luxury &amp; Premium &amp; Mainstream</td>\n",
       "      <td>Footwear</td>\n",
       "      <td>Nine West</td>\n",
       "      <td>Premier Brands</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sycamore Partners</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metric Value</td>\n",
       "      <td>1966799.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4216.0</td>\n",
       "      <td>16080.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1365 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       period period_end_date                  compset_group  \\\n",
       "68827  Weekly      2016-08-27  Luxury & Premium & Mainstream   \n",
       "68828  Weekly      2016-03-19  Luxury & Premium & Mainstream   \n",
       "68829  Weekly      2023-08-26  Luxury & Premium & Mainstream   \n",
       "68830  Weekly      2018-11-03  Luxury & Premium & Mainstream   \n",
       "68831  Weekly      2019-03-16  Luxury & Premium & Mainstream   \n",
       "...       ...             ...                            ...   \n",
       "70187  Weekly      2023-07-29  Luxury & Premium & Mainstream   \n",
       "70188  Weekly      2023-06-24  Luxury & Premium & Mainstream   \n",
       "70189  Weekly      2019-12-07  Luxury & Premium & Mainstream   \n",
       "70190  Weekly      2018-03-24  Luxury & Premium & Mainstream   \n",
       "70191  Weekly      2023-09-02  Luxury & Premium & Mainstream   \n",
       "\n",
       "                                  compset  \\\n",
       "68827                            Footwear   \n",
       "68828       Luxury & Premium & Mainstream   \n",
       "68829  US Softlines Analyst Interest List   \n",
       "68830                            Footwear   \n",
       "68831       Luxury & Premium & Mainstream   \n",
       "...                                   ...   \n",
       "70187  US Softlines Analyst Interest List   \n",
       "70188  US Softlines Analyst Interest List   \n",
       "70189  US Softlines Analyst Interest List   \n",
       "70190                            Footwear   \n",
       "70191                            Footwear   \n",
       "\n",
       "      business_entity_doing_business_as_name legal_entity_name  \\\n",
       "68827                              Nine West    Premier Brands   \n",
       "68828                              Nine West    Premier Brands   \n",
       "68829                              Nine West    Premier Brands   \n",
       "68830                              Nine West    Premier Brands   \n",
       "68831                              Nine West    Premier Brands   \n",
       "...                                      ...               ...   \n",
       "70187                              Nine West    Premier Brands   \n",
       "70188                              Nine West    Premier Brands   \n",
       "70189                              Nine West    Premier Brands   \n",
       "70190                              Nine West    Premier Brands   \n",
       "70191                              Nine West    Premier Brands   \n",
       "\n",
       "      domicile_country_name ultimate_parent_legal_entity_name  \\\n",
       "68827                   NaN                 Sycamore Partners   \n",
       "68828                   NaN                 Sycamore Partners   \n",
       "68829                   NaN                 Sycamore Partners   \n",
       "68830                   NaN                 Sycamore Partners   \n",
       "68831                   NaN                 Sycamore Partners   \n",
       "...                     ...                               ...   \n",
       "70187                   NaN                 Sycamore Partners   \n",
       "70188                   NaN                 Sycamore Partners   \n",
       "70189                   NaN                 Sycamore Partners   \n",
       "70190                   NaN                 Sycamore Partners   \n",
       "70191                   NaN                 Sycamore Partners   \n",
       "\n",
       "      primary_exchange_name calculation_type  followers  pictures  videos  \\\n",
       "68827                   NaN     Metric Value        NaN     282.0    11.0   \n",
       "68828                   NaN     Metric Value        NaN     278.0     5.0   \n",
       "68829                   NaN     Metric Value  1966375.0     315.0    34.0   \n",
       "68830                   NaN     Metric Value  1101163.0     307.0    24.0   \n",
       "68831                   NaN     Metric Value  1196891.0     382.0    23.0   \n",
       "...                     ...              ...        ...       ...     ...   \n",
       "70187                   NaN     Metric Value  1963930.0     361.0    40.0   \n",
       "70188                   NaN     Metric Value  1961784.0     370.0    41.0   \n",
       "70189                   NaN     Metric Value  1456414.0     505.0    40.0   \n",
       "70190                   NaN     Metric Value   955823.0     350.0    17.0   \n",
       "70191                   NaN     Metric Value  1966799.0     285.0    31.0   \n",
       "\n",
       "       comments     likes  \n",
       "68827    3154.0  162063.0  \n",
       "68828    4547.0  123483.0  \n",
       "68829    4235.0   17044.0  \n",
       "68830    5819.0  197415.0  \n",
       "68831    5812.0  237443.0  \n",
       "...         ...       ...  \n",
       "70187    3148.0   21942.0  \n",
       "70188     425.0   37852.0  \n",
       "70189    4015.0  171113.0  \n",
       "70190    4481.0  174004.0  \n",
       "70191    4216.0   16080.0  \n",
       "\n",
       "[1365 rows x 15 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['business_entity_doing_business_as_name'] == 'Nine West']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/david/code/datathon24-personal/data/skylab_instagram_datathon_dataset.csv\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH, sep=\";\")\n",
    "\n",
    "\n",
    "def preprocess_data(df, missing_values_cutoff=0.7):\n",
    "\n",
    "    df = df.drop(columns=[\"period\", \"calculation_type\", \"compset\", \"compset_group\", \"legal_entity_name\", \"ultimate_parent_legal_entity_name\", \"primary_exchange_name\"])\n",
    "    df[\"period_end_date\"] = pd.to_datetime(df[\"period_end_date\"])\n",
    "\n",
    "    df = df.rename(columns={'business_entity_doing_business_as_name': 'brand', 'period_end_date': 'date'})\n",
    "\n",
    "    df = df[df['brand'] != \"All Brands\"]\n",
    "    df = df[df['brand'] != \"Boca\"]\n",
    "\n",
    "    df = df.groupby(['brand', 'date']).first().reset_index()\n",
    "\n",
    "    def correct_country_name(name):\n",
    "        country_map = {\n",
    "            \"Hong Kong\": \"China\",\n",
    "            \"China;Hong Kong\": \"China\",\n",
    "            \";France\": \"France\",\n",
    "            \";\": None,\n",
    "            \"Belgium;\": \"Belgium\"\n",
    "        }\n",
    "        if name in country_map.keys():\n",
    "            return country_map[name]\n",
    "        return name\n",
    "\n",
    "    df['domicile_country_name'] = df['domicile_country_name'].apply(correct_country_name)\n",
    "\n",
    "\n",
    "    categorical_features = [\"domicile_country_name\"]\n",
    "    for feature in categorical_features:\n",
    "        df = pd.get_dummies(df, columns=[feature], prefix=feature, dummy_na=True, dtype=int)\n",
    "\n",
    "    # TODO: remove bad data\n",
    "    na_frac = df[['brand', 'followers', 'pictures',\n",
    "        'videos', 'comments', 'likes']].groupby('brand').apply(lambda x: x.iloc[:,1:].isna().sum()/len(x))\n",
    "\n",
    "    bad_brands = list(na_frac[na_frac.max(axis=1) > missing_values_cutoff].index)\n",
    "\n",
    "    df = df[~df['brand'].isin(bad_brands)]\n",
    "\n",
    "\n",
    "    # TODO: add additional features\n",
    "    df['engagement'] = df['comments'] + df['likes']\n",
    "    df['engagement_rate'] = df['engagement']/df['followers']\n",
    "    df['engagement_rate_per_post'] =  df['engagement_rate']/(df['videos'] + df['pictures'])\n",
    "\n",
    "\n",
    "\n",
    "    # TODO: normalize values\n",
    "    normalize_cols = [\"followers\", \"pictures\", \"videos\", \"comments\", \"likes\", \"engagement\", \"engagement_rate\", \"engagement_rate_per_post\"]\n",
    "\n",
    "    for col in normalize_cols:\n",
    "        m = df[col].mean()\n",
    "        s = df[col].std()\n",
    "        df[col] = (df[col] - m)/s\n",
    "\n",
    "    # TODO: impute missing values\n",
    "  \n",
    "    # TODO: impute missing values\n",
    "    df = df.groupby('brand').apply(lambda group: group.fillna(method='ffill'))\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    df = df.groupby('brand').apply(lambda group: group.fillna(method='bfill'))\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_data_lstm(df, sequence_length=10, prediction_dist=4, missing_values_cutoff=0.7, test_fraction=0.2):\n",
    "\n",
    "    df = df.drop(columns=[\"period\", \"calculation_type\", \"compset\", \"compset_group\", \"legal_entity_name\", \"ultimate_parent_legal_entity_name\", \"primary_exchange_name\"])\n",
    "    df[\"period_end_date\"] = pd.to_datetime(df[\"period_end_date\"])\n",
    "\n",
    "    df = df.rename(columns={'business_entity_doing_business_as_name': 'brand', 'period_end_date': 'date'})\n",
    "\n",
    "    df = df[df['brand'] != \"All Brands\"]\n",
    "    df = df[df['brand'] != \"Boca\"]\n",
    "\n",
    "    df = df.groupby(['brand', 'date']).first().reset_index()\n",
    "\n",
    "    def correct_country_name(name):\n",
    "        country_map = {\n",
    "            \"Hong Kong\": \"China\",\n",
    "            \"China;Hong Kong\": \"China\",\n",
    "            \";France\": \"France\",\n",
    "            \";\": None,\n",
    "            \"Belgium;\": \"Belgium\"\n",
    "        }\n",
    "        if name in country_map.keys():\n",
    "            return country_map[name]\n",
    "        return name\n",
    "\n",
    "    df['domicile_country_name'] = df['domicile_country_name'].apply(correct_country_name)\n",
    "\n",
    "\n",
    "    categorical_features = [\"domicile_country_name\"]\n",
    "    for feature in categorical_features:\n",
    "        df = pd.get_dummies(df, columns=[feature], prefix=feature, dummy_na=True, dtype=int)\n",
    "\n",
    "    # TODO: remove bad data\n",
    "    na_frac = df[['brand', 'followers', 'pictures',\n",
    "        'videos', 'comments', 'likes']].groupby('brand').apply(lambda x: x.iloc[:,1:].isna().sum()/len(x))\n",
    "\n",
    "    bad_brands = list(na_frac[na_frac.max(axis=1) > missing_values_cutoff].index)\n",
    "\n",
    "    df = df[~df['brand'].isin(bad_brands)]\n",
    "\n",
    "\n",
    "    # TODO: add additional features\n",
    "    df['engagement'] = df['comments'] + df['likes']\n",
    "    df['engagement_rate'] = df['engagement']/df['followers']\n",
    "    df['engagement_rate_per_post'] =  df['engagement_rate']/(df['videos'] + df['pictures'])\n",
    "\n",
    "\n",
    "\n",
    "    # Step 1: Sort the dataframe by time\n",
    "    df_sorted = df.sort_values(by='date')\n",
    "\n",
    "    # Step 2: Group the dataframe by 'Brand'\n",
    "    grouped = df_sorted.groupby('brand')\n",
    "\n",
    "    # Step 3: Define an empty dataframe for train and test sets\n",
    "    train_df = pd.DataFrame(columns=df.columns)  # Columns same as original dataframe\n",
    "    test_df = pd.DataFrame(columns=df.columns)   # Columns same as original dataframe\n",
    "\n",
    "    # Step 4: Iterate over each group and split into train and test sets\n",
    "    for _, group in grouped:\n",
    "        n_rows = len(group)\n",
    "        n_test = int(test_fraction * n_rows)  # 20% of rows for test set\n",
    "\n",
    "        # Add last 20% of rows to test set\n",
    "        test_df = pd.concat([test_df, group.iloc[-n_test:]])\n",
    "\n",
    "        # Add remaining rows to train set\n",
    "        train_df = pd.concat([train_df, group.iloc[:-n_test]])\n",
    "\n",
    "    # Step 5: Reset index for both train and test dataframes\n",
    "    train_df.reset_index(drop=True, inplace=True)\n",
    "    test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "    # TODO: normalize values\n",
    "    normalize_cols = [\"followers\", \"pictures\", \"videos\", \"comments\", \"likes\", \"engagement\", \"engagement_rate\", \"engagement_rate_per_post\"]\n",
    "\n",
    "    for col in normalize_cols:\n",
    "        m = train_df[col].mean()\n",
    "        s = train_df[col].std()\n",
    "        train_df[col] = (train_df[col] - m)/s\n",
    "        test_df[col] = (test_df[col] - m)/s\n",
    "\n",
    "\n",
    "    # TODO: impute missing values\n",
    "  \n",
    "    # TODO: impute missing values\n",
    "    train_df = train_df.groupby('brand').apply(lambda group: group.fillna(method='ffill'))\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "    train_df = train_df.groupby('brand').apply(lambda group: group.fillna(method='bfill'))\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "    test_df = test_df.groupby('brand').apply(lambda group: group.fillna(method='ffill'))\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "    test_df = test_df.groupby('brand').apply(lambda group: group.fillna(method='bfill'))\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "    # TODO: create sequences\n",
    "\n",
    "    # TODO: split df into brands\n",
    "    # sequence per brand\n",
    "    # label\n",
    "\n",
    "    label_col = \"engagement_rate_per_post\"\n",
    "\n",
    "    train_sequences = []\n",
    "    train_labels = []\n",
    "    test_sequences = []\n",
    "    test_labels = []\n",
    "\n",
    "\n",
    "    for bi, brand in enumerate(df['brand'].unique()):\n",
    "\n",
    "        brand_train_df = train_df[train_df['brand'] == brand]\n",
    "\n",
    "        cols = [c for c in train_df.columns if (c != \"brand\" and c != \"date\")]\n",
    "        brand_train_df = brand_train_df[cols]\n",
    "\n",
    "        for i in range(len(brand_train_df) - (sequence_length + prediction_dist)):\n",
    "            sequence = brand_train_df.iloc[i:i + sequence_length].values\n",
    "            train_sequences.append(sequence)\n",
    "\n",
    "            sequence_labels = brand_train_df.iloc[i+sequence_length+prediction_dist][label_col]\n",
    "            train_labels.append(sequence_labels)\n",
    "        \n",
    "        brand_test_df = test_df[test_df['brand'] == brand]\n",
    "\n",
    "        brand_test_df = brand_test_df[cols]\n",
    "\n",
    "\n",
    "        for i in range(len(brand_test_df) - (sequence_length + prediction_dist)):\n",
    "            sequence = brand_test_df.iloc[i:i + sequence_length].values\n",
    "            test_sequences.append(sequence)\n",
    "\n",
    "            sequence_labels = brand_test_df.iloc[i+sequence_length+prediction_dist][label_col]\n",
    "            test_labels.append(sequence_labels)\n",
    "\n",
    "\n",
    "    return train_sequences, train_labels, test_sequences, test_labels\n",
    "\n",
    "# X_train, y_train, X_test, y_test = prepare_data_lstm(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5459/2876099942.py:39: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  'videos', 'comments', 'likes']].groupby('brand').apply(lambda x: x.iloc[:,1:].isna().sum()/len(x))\n",
      "/tmp/ipykernel_5459/2876099942.py:64: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.groupby('brand').apply(lambda group: group.fillna(method='ffill'))\n",
      "/tmp/ipykernel_5459/2876099942.py:64: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('brand').apply(lambda group: group.fillna(method='ffill'))\n",
      "/tmp/ipykernel_5459/2876099942.py:67: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.groupby('brand').apply(lambda group: group.fillna(method='bfill'))\n",
      "/tmp/ipykernel_5459/2876099942.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('brand').apply(lambda group: group.fillna(method='bfill'))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>date</th>\n",
       "      <th>followers</th>\n",
       "      <th>pictures</th>\n",
       "      <th>videos</th>\n",
       "      <th>comments</th>\n",
       "      <th>likes</th>\n",
       "      <th>domicile_country_name_Australia</th>\n",
       "      <th>domicile_country_name_Belgium</th>\n",
       "      <th>domicile_country_name_Brazil</th>\n",
       "      <th>...</th>\n",
       "      <th>domicile_country_name_Singapore</th>\n",
       "      <th>domicile_country_name_Spain</th>\n",
       "      <th>domicile_country_name_Sweden</th>\n",
       "      <th>domicile_country_name_Switzerland</th>\n",
       "      <th>domicile_country_name_United Kingdom of Great Britain and Northern Ireland</th>\n",
       "      <th>domicile_country_name_United States of America</th>\n",
       "      <th>domicile_country_name_nan</th>\n",
       "      <th>engagement</th>\n",
       "      <th>engagement_rate</th>\n",
       "      <th>engagement_rate_per_post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24S</td>\n",
       "      <td>2017-05-06</td>\n",
       "      <td>-0.286451</td>\n",
       "      <td>-0.429305</td>\n",
       "      <td>-0.302278</td>\n",
       "      <td>-0.177231</td>\n",
       "      <td>-0.251962</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.253701</td>\n",
       "      <td>2.843436</td>\n",
       "      <td>0.996963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24S</td>\n",
       "      <td>2017-05-13</td>\n",
       "      <td>-0.286451</td>\n",
       "      <td>-0.429305</td>\n",
       "      <td>-0.302278</td>\n",
       "      <td>-0.177231</td>\n",
       "      <td>-0.251962</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.253701</td>\n",
       "      <td>2.843436</td>\n",
       "      <td>0.996963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24S</td>\n",
       "      <td>2017-05-20</td>\n",
       "      <td>-0.286451</td>\n",
       "      <td>-0.429305</td>\n",
       "      <td>-0.302278</td>\n",
       "      <td>-0.177231</td>\n",
       "      <td>-0.251962</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.253701</td>\n",
       "      <td>2.843436</td>\n",
       "      <td>0.996963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24S</td>\n",
       "      <td>2017-05-27</td>\n",
       "      <td>-0.286451</td>\n",
       "      <td>-0.429305</td>\n",
       "      <td>-0.302278</td>\n",
       "      <td>-0.177231</td>\n",
       "      <td>-0.251962</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.253701</td>\n",
       "      <td>2.843436</td>\n",
       "      <td>0.996963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24S</td>\n",
       "      <td>2017-06-03</td>\n",
       "      <td>-0.286451</td>\n",
       "      <td>-0.362194</td>\n",
       "      <td>-0.302278</td>\n",
       "      <td>-0.176280</td>\n",
       "      <td>-0.251120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.252847</td>\n",
       "      <td>2.843436</td>\n",
       "      <td>0.996963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289787</th>\n",
       "      <td>shopDisney</td>\n",
       "      <td>2023-08-19</td>\n",
       "      <td>0.029807</td>\n",
       "      <td>0.540083</td>\n",
       "      <td>0.369886</td>\n",
       "      <td>-0.121598</td>\n",
       "      <td>-0.148823</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.150272</td>\n",
       "      <td>-0.450343</td>\n",
       "      <td>-0.576640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289788</th>\n",
       "      <td>shopDisney</td>\n",
       "      <td>2023-08-26</td>\n",
       "      <td>0.030007</td>\n",
       "      <td>0.536355</td>\n",
       "      <td>0.493344</td>\n",
       "      <td>-0.114374</td>\n",
       "      <td>-0.129334</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.130798</td>\n",
       "      <td>-0.408335</td>\n",
       "      <td>-0.572330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289789</th>\n",
       "      <td>shopDisney</td>\n",
       "      <td>2023-09-02</td>\n",
       "      <td>0.030318</td>\n",
       "      <td>0.547540</td>\n",
       "      <td>0.493344</td>\n",
       "      <td>-0.106583</td>\n",
       "      <td>-0.119321</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.120706</td>\n",
       "      <td>-0.386775</td>\n",
       "      <td>-0.570085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289790</th>\n",
       "      <td>shopDisney</td>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>0.030706</td>\n",
       "      <td>0.513984</td>\n",
       "      <td>0.424756</td>\n",
       "      <td>-0.110607</td>\n",
       "      <td>-0.121882</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.123329</td>\n",
       "      <td>-0.392793</td>\n",
       "      <td>-0.569314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289791</th>\n",
       "      <td>shopDisney</td>\n",
       "      <td>2023-09-16</td>\n",
       "      <td>0.031116</td>\n",
       "      <td>0.458058</td>\n",
       "      <td>0.644238</td>\n",
       "      <td>-0.106803</td>\n",
       "      <td>-0.123613</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.124965</td>\n",
       "      <td>-0.396685</td>\n",
       "      <td>-0.569900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>289792 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             brand       date  followers  pictures    videos  comments  \\\n",
       "0              24S 2017-05-06  -0.286451 -0.429305 -0.302278 -0.177231   \n",
       "1              24S 2017-05-13  -0.286451 -0.429305 -0.302278 -0.177231   \n",
       "2              24S 2017-05-20  -0.286451 -0.429305 -0.302278 -0.177231   \n",
       "3              24S 2017-05-27  -0.286451 -0.429305 -0.302278 -0.177231   \n",
       "4              24S 2017-06-03  -0.286451 -0.362194 -0.302278 -0.176280   \n",
       "...            ...        ...        ...       ...       ...       ...   \n",
       "289787  shopDisney 2023-08-19   0.029807  0.540083  0.369886 -0.121598   \n",
       "289788  shopDisney 2023-08-26   0.030007  0.536355  0.493344 -0.114374   \n",
       "289789  shopDisney 2023-09-02   0.030318  0.547540  0.493344 -0.106583   \n",
       "289790  shopDisney 2023-09-09   0.030706  0.513984  0.424756 -0.110607   \n",
       "289791  shopDisney 2023-09-16   0.031116  0.458058  0.644238 -0.106803   \n",
       "\n",
       "           likes  domicile_country_name_Australia  \\\n",
       "0      -0.251962                                0   \n",
       "1      -0.251962                                0   \n",
       "2      -0.251962                                0   \n",
       "3      -0.251962                                0   \n",
       "4      -0.251120                                0   \n",
       "...          ...                              ...   \n",
       "289787 -0.148823                                0   \n",
       "289788 -0.129334                                0   \n",
       "289789 -0.119321                                0   \n",
       "289790 -0.121882                                0   \n",
       "289791 -0.123613                                0   \n",
       "\n",
       "        domicile_country_name_Belgium  domicile_country_name_Brazil  ...  \\\n",
       "0                                   0                             0  ...   \n",
       "1                                   0                             0  ...   \n",
       "2                                   0                             0  ...   \n",
       "3                                   0                             0  ...   \n",
       "4                                   0                             0  ...   \n",
       "...                               ...                           ...  ...   \n",
       "289787                              0                             0  ...   \n",
       "289788                              0                             0  ...   \n",
       "289789                              0                             0  ...   \n",
       "289790                              0                             0  ...   \n",
       "289791                              0                             0  ...   \n",
       "\n",
       "        domicile_country_name_Singapore  domicile_country_name_Spain  \\\n",
       "0                                     0                            0   \n",
       "1                                     0                            0   \n",
       "2                                     0                            0   \n",
       "3                                     0                            0   \n",
       "4                                     0                            0   \n",
       "...                                 ...                          ...   \n",
       "289787                                0                            0   \n",
       "289788                                0                            0   \n",
       "289789                                0                            0   \n",
       "289790                                0                            0   \n",
       "289791                                0                            0   \n",
       "\n",
       "        domicile_country_name_Sweden  domicile_country_name_Switzerland  \\\n",
       "0                                  0                                  0   \n",
       "1                                  0                                  0   \n",
       "2                                  0                                  0   \n",
       "3                                  0                                  0   \n",
       "4                                  0                                  0   \n",
       "...                              ...                                ...   \n",
       "289787                             0                                  0   \n",
       "289788                             0                                  0   \n",
       "289789                             0                                  0   \n",
       "289790                             0                                  0   \n",
       "289791                             0                                  0   \n",
       "\n",
       "        domicile_country_name_United Kingdom of Great Britain and Northern Ireland  \\\n",
       "0                                                       0                            \n",
       "1                                                       0                            \n",
       "2                                                       0                            \n",
       "3                                                       0                            \n",
       "4                                                       0                            \n",
       "...                                                   ...                            \n",
       "289787                                                  0                            \n",
       "289788                                                  0                            \n",
       "289789                                                  0                            \n",
       "289790                                                  0                            \n",
       "289791                                                  0                            \n",
       "\n",
       "        domicile_country_name_United States of America  \\\n",
       "0                                                    0   \n",
       "1                                                    0   \n",
       "2                                                    0   \n",
       "3                                                    0   \n",
       "4                                                    0   \n",
       "...                                                ...   \n",
       "289787                                               1   \n",
       "289788                                               1   \n",
       "289789                                               1   \n",
       "289790                                               1   \n",
       "289791                                               1   \n",
       "\n",
       "        domicile_country_name_nan  engagement  engagement_rate  \\\n",
       "0                               0   -0.253701         2.843436   \n",
       "1                               0   -0.253701         2.843436   \n",
       "2                               0   -0.253701         2.843436   \n",
       "3                               0   -0.253701         2.843436   \n",
       "4                               0   -0.252847         2.843436   \n",
       "...                           ...         ...              ...   \n",
       "289787                          0   -0.150272        -0.450343   \n",
       "289788                          0   -0.130798        -0.408335   \n",
       "289789                          0   -0.120706        -0.386775   \n",
       "289790                          0   -0.123329        -0.392793   \n",
       "289791                          0   -0.124965        -0.396685   \n",
       "\n",
       "        engagement_rate_per_post  \n",
       "0                       0.996963  \n",
       "1                       0.996963  \n",
       "2                       0.996963  \n",
       "3                       0.996963  \n",
       "4                       0.996963  \n",
       "...                          ...  \n",
       "289787                 -0.576640  \n",
       "289788                 -0.572330  \n",
       "289789                 -0.570085  \n",
       "289790                 -0.569314  \n",
       "289791                 -0.569900  \n",
       "\n",
       "[289792 rows x 32 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datathon24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
